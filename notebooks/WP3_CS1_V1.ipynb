{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9ab5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:25:13.198532Z",
     "start_time": "2023-08-16T14:25:12.185239Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import os\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as ltb\n",
    "import catboost as ctb\n",
    "from skrebate import ReliefF\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectPercentile\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, auc, roc_curve, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold, StratifiedKFold, cross_validate\n",
    "seed(42)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from tabulate import tabulate\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4e78f-3804-4eb2-8fe8-b2f91028105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load our own modules\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    print(module_path)\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d78ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:26:14.079486Z",
     "start_time": "2023-08-16T14:26:14.006993Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_pickle(\n",
    "    os.path.join(utils.DATA_DIR_INTERIM, \"dev_df.pkl\"))\n",
    "\n",
    "response_variable = 'dysphagia_at_m6_2plus'\n",
    "\n",
    "df = df.drop(columns = 'dysphagia_at_m6_3plus') # other outcome, should not be a feature\n",
    "df = df.dropna(how='any', subset = [response_variable]) # new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will return variable list that have correlation more than cut(0.8)\n",
    "def find_correlated_features(df, threshold=0.8):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    # Calculate the average correlation for each feature\n",
    "    avg_corr = corr_matrix.mean(axis=1)\n",
    "    \n",
    "    # Create an upper triangle mask to focus on unique pairs\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Initialize a list to store columns to drop\n",
    "    drop_columns = []\n",
    "\n",
    "    # Iterate through the upper triangle of the correlation matrix\n",
    "    for row in range(len(upper_triangle) - 1):\n",
    "        col_idx = row + 1\n",
    "        for col in range(col_idx, len(upper_triangle)):\n",
    "            # Check if correlation is above the threshold\n",
    "            if upper_triangle.iloc[row, col] > threshold:\n",
    "                # Compare average correlations to decide which feature to drop\n",
    "                if avg_corr.iloc[row] > avg_corr.iloc[col]:\n",
    "                    drop_columns.append(row)\n",
    "                else:\n",
    "                    drop_columns.append(col)\n",
    "    # Convert the list of columns to drop into a set to get unique values\n",
    "    drop_columns = set(drop_columns)\n",
    "    # Get the names of correlated features\n",
    "    correlated_features = df.columns[list(drop_columns)]\n",
    "    \n",
    "    return correlated_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of column names\n",
    "variables = df.columns\n",
    "thresh = 40 # Set the threshold for missing values\n",
    "# Initialize lists to store selected and removed features\n",
    "keep = [ ]\n",
    "rem = []\n",
    "print(correlated_variables)\n",
    "\n",
    "def get_missing_val_percentage(df):\n",
    "    return (df.isnull().sum()* 100 / len(df))\n",
    "\n",
    "def preprocessing(df, test_size):\n",
    "    \n",
    "    # Convert categorical and boolean varialbles to numeric using LabelEncoder\n",
    "    cat_cols = df.select_dtypes(include=['bool', 'object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        labelencoder = LabelEncoder()\n",
    "        df[col] = labelencoder.fit_transform(df[col])\n",
    "        \n",
    "    # remove rows with missing 'response variable'\n",
    "    df = df.dropna(how='any', subset = [response_variable])\n",
    "    print('Shape of data after excluding missing response:', np.shape(df))\n",
    "    \n",
    "    # TODO: Convert date variables (if any)\n",
    "    # date variables are not in the simulated data\n",
    "    \n",
    "    # Delete columns with more than threshold NaN\n",
    "    missing_per = get_missing_val_percentage(df)     \n",
    "    keep = df.columns[missing_per <= thresh]\n",
    "    df = df[keep]\n",
    "    print('Shape of data after removing cols with less than %.2f percent values missing:' % (thresh), df.shape)\n",
    "   \n",
    "    # Remove correlated features \n",
    "    df = df.drop([x for x in correlated_variables if x in df.columns], axis=1)\n",
    "    print('Shape of data after removing correlated features:', np.shape(df))\n",
    "       \n",
    "    \n",
    "    # TODO: find outliers and remove\n",
    "    \n",
    "    # split data\n",
    "    random.seed(42)\n",
    "    # Save original data set\n",
    "    original = df\n",
    "    Y = df[response_variable]\n",
    "    X = df.drop(response_variable, axis=1)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, stratify = Y, random_state=123)\n",
    "    \n",
    "    # Data imputation starts here\n",
    "    original_X_train = X_train\n",
    "    original_X_test = X_test\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy = \"most_frequent\")\n",
    "    # imputeX = KNNImputer(missing_values=np.nan, n_neighbors = 3, weights='distance')\n",
    "    # imputeX = IterativeImputer(max_iter=5, random_state=0)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    # Scale data: Scale imputed and non imputed data seperately.\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train_imputed = scaler.fit_transform(X_train_imputed)\n",
    "    X_test_imputed = scaler.transform(X_test_imputed)\n",
    "        \n",
    "    # print unique value count of response variable in train and test set\n",
    "    unique_train, counts_train = numpy.unique(Y_train.to_numpy(), return_counts=True)\n",
    "    unique_test, counts_test = numpy.unique(Y_test.to_numpy(), return_counts=True)\n",
    "    print(\"Train - \", unique_train, counts_train)\n",
    "    print(\"Test - \", unique_test, counts_test)\n",
    "    \n",
    "    # Convert scaled arrays back to DataFrames\n",
    "    X_train = pd.DataFrame(X_train, columns = original_X_train.columns, index=original_X_train.index)\n",
    "    X_test = pd.DataFrame(X_test, columns = original_X_train.columns, index=original_X_test.index)\n",
    "    \n",
    "    X_train_imputed = pd.DataFrame(X_train_imputed, columns = original_X_train.columns, index=original_X_train.index)\n",
    "    X_test_imputed = pd.DataFrame(X_test_imputed, columns = original_X_train.columns, index=original_X_test.index)\n",
    "    \n",
    "    return df, X_train, X_test, Y_train, Y_test, X, Y, X_train_imputed, X_test_imputed\n",
    "\n",
    "df, X_train, X_test, Y_train, Y_test, X, Y, X_train_imputed, X_test_imputed = preprocessing(df, 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82494e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, X_train, Y_train, n_splits=10):\n",
    "    # Create an array to store balanced accuracy scores for each fold\n",
    "    balacc_arr = []\n",
    "    # Initialize StratifiedKFold with the number of splits\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "    # Loop through each fold in the cross-validation\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, Y_train)):\n",
    "        # Split the training and testing data for this fold\n",
    "        X_train1 = X_train.iloc[train_index]\n",
    "        X_test1 = X_train.iloc[test_index]\n",
    "        y_train1 = Y_train.iloc[train_index]\n",
    "        y_test1 = Y_train.iloc[test_index]\n",
    "\n",
    "        # Fit the model on the training data for this fold\n",
    "        model.fit(X_train1, y_train1)\n",
    "        # Get predicted probabilities for the positive class\n",
    "        y_scores = model.predict_proba(X_test1)\n",
    "        y_sc = y_scores[:, 1]\n",
    "        # Calculate ROC curve and find optimal threshold for classification\n",
    "        fpr, tpr, thresholds = roc_curve(y_test1, y_sc)\n",
    "        optimal_idx = np.argmax(np.sqrt(tpr * (1 - fpr)))\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        # Apply the optimal threshold for prediction and calculate balanced accuracy\n",
    "        model_pred = (y_sc >= optimal_threshold).astype(int)\n",
    "        confusion_matrix_model = confusion_matrix(y_test1, model_pred)\n",
    "        acc_bal = confusion_matrix_model.diagonal() / confusion_matrix_model.sum(axis=1)\n",
    "        balacc_arr.append(np.sum(acc_bal) / 2)\n",
    "    \n",
    "    # Calculate the variance of balanced accuracy scores across all folds\n",
    "    variance_bal = np.var(balacc_arr, ddof=1)\n",
    "\n",
    "    print(\"Cross validation variance Balance acc:\", variance_bal)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve with the optimal threshold marked\n",
    "def plot_roc_curve(fpr, tpr, optimal_idx):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label='Best') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Find the optimal threshold based on ROC curve (G-mean)\n",
    "def optimal_thresh(model, X, Y):\n",
    "    y_scores = model.predict_proba(X)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(Y, y_scores)\n",
    "    optimal_idx = np.argmax(np.sqrt(tpr * (1-fpr)))\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Display confusion matrix and accuracy results\n",
    "def get_results(model, X, Y, pred):\n",
    "    confusion_matrix_model = confusion_matrix(Y, pred)\n",
    "    test_acc = model.score(X, Y)\n",
    "    \n",
    "    results_table = [\n",
    "        [\"Confusion Matrix\", confusion_matrix_model],\n",
    "        [\"Accuracy\", test_acc]\n",
    "    ]\n",
    "    \n",
    "    print(tabulate(results_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# Evaluate the model's performance metrics\n",
    "def evaluate_model(model, X_test, Y_test, optimal_threshold):\n",
    "    pred = (model.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    score = round(roc_auc_score(Y_test, y_scores[:, 1]), 4)\n",
    "    confusion_matrix_model = confusion_matrix(Y_test, pred)\n",
    "    acc = confusion_matrix_model.diagonal() / confusion_matrix_model.sum(axis=1)\n",
    "    avg_acc = np.sum(acc) / 2\n",
    "    f1 = metrics.f1_score(pred, Y_test, average='micro')\n",
    "    \n",
    "    results_table = [\n",
    "        [\"Test ROC Score\", score],\n",
    "        [\"Test Classwise Accuracy [Class 0, Class 1]\", acc],\n",
    "        [\"Test Average Accuracy\", avg_acc],\n",
    "        [\"Test F1 Score\", f1]\n",
    "    ]\n",
    "    \n",
    "    print(tabulate(results_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# Train the model, evaluate on train and test sets, and return the trained model\n",
    "def train_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    model = cross_val(model, X_train, Y_train)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    optimal_threshold = optimal_thresh(model, X_test, Y_test)\n",
    "    pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold).astype(int)\n",
    "    optimal_threshold_train = optimal_thresh(model, X_train, Y_train)\n",
    "    pred_train = (model.predict_proba(X_train)[:, 1] >= optimal_threshold_train).astype(int)\n",
    "    \n",
    "    print('===== Train set =====')\n",
    "    get_results(model, X_train, Y_train, pred_train)\n",
    "    print('===== Test set =====')\n",
    "    get_results(model, X_test, Y_test, pred)\n",
    "\n",
    "    evaluate_model(model, X_test, Y_test, optimal_threshold_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train multiple machine learning models\n",
    "def init(models, X_train, X_test, X_train_imputed, X_test_imputed, Y_train, Y_test):\n",
    "    # Dictionary to store trained models\n",
    "    trained_models = {}\n",
    "    # Loop through each model in the list\n",
    "    for model in models:\n",
    "        # Set X_train and X_test based on the model type\n",
    "        X_t = X_train\n",
    "        X_te = X_test\n",
    "        model_name = model.__class__.__name__\n",
    "        # If model requires imputed data, update X_train and X_test accordingly\n",
    "        if(model_name == 'AdaBoostClassifier' or model_name == 'RandomForestClassifier' or model_name == 'LogisticRegression'):\n",
    "            X_t = X_train_imputed\n",
    "            X_te = X_test_imputed\n",
    "        print(\"Model:\", model_name)\n",
    "        \n",
    "        # Train the model \n",
    "        trained_model = train_model(model, X_t, Y_train, X_te, Y_test)\n",
    "        # Store the trained model in the dictionary\n",
    "        trained_models[model_name] = trained_model\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "    return trained_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f068aa",
   "metadata": {},
   "source": [
    "# Without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c26c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune parameters accordingly\n",
    "xgboost =XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eta = 0.1,\n",
    "        max_depth = 4, \n",
    "        max_delta_step = 10,\n",
    "        subsample = 0.5,\n",
    "        colsample_bytree = 1,\n",
    "        tree_method = \"auto\",\n",
    "        process_type = \"default\",\n",
    "        num_parallel_tree=7,\n",
    "        objective='multi:softmax',\n",
    "        min_child_weight = 3,\n",
    "        booster='gbtree',\n",
    "        eval_metric = \"mlogloss\",\n",
    "        alpha  = 0.08,\n",
    "        num_class = 2\n",
    "    )\n",
    "\n",
    "lgb = ltb.LGBMClassifier(use_missing = True, \n",
    "                         learning_rate = 0.01,  # 0.045 (0.03)\n",
    "                         scale_pos_weight=1,\n",
    "                         max_depth =4, random_state=0 )\n",
    "\n",
    "catboost = ctb.CatBoostClassifier(iterations=10,\n",
    "                          learning_rate=0.1,\n",
    "                          scale_pos_weight=0.4,\n",
    "                          depth=3,\n",
    "                          verbose=False)\n",
    "\n",
    "adaboost = AdaBoostClassifier(random_state=0,\n",
    "                              learning_rate=0.1,\n",
    "                              n_estimators=1000,\n",
    "                              algorithm = \"SAMME.R\") \n",
    "\n",
    "rf = RandomForestClassifier(max_depth=4,\n",
    "                             n_estimators = np.shape(X_test)[1],\n",
    "                             criterion = 'gini',\n",
    "                             class_weight = 'balanced',\n",
    "                              ccp_alpha=0.01,\n",
    "                             random_state=0)\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    tol = 5e-4,\n",
    "    C=4,\n",
    "    class_weight='balanced',\n",
    "    random_state=0,\n",
    "    solver = 'saga'\n",
    ")\n",
    "\n",
    "# List of machine learning models to be trained\n",
    "models = [xgboost]#, lgb, catboost, adaboost, rf, lr]\n",
    "\n",
    "# Initialize and train the models using different data variations (original data and imputed data)\n",
    "trained_models_case1 = init(models, X_train, X_test, X_train_imputed, X_test_imputed, Y_train, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbaced-c647-4b6f-8608-f5d64fd14a46",
   "metadata": {},
   "source": [
    "## SHAP values without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebd117-f24b-42f1-aff2-57a5d24e25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global SHAP plots\n",
    "\n",
    "# Select the model you want to explain (XGBClassifier in this case)\n",
    "selected_model = trained_models_case1['XGBClassifier']\n",
    "\n",
    "# Create an explainer using SHAP\n",
    "explainer = shap.Explainer(selected_model, X_train)\n",
    "\n",
    "# Calculate SHAP values for the data using the explainer\n",
    "shap_values = explainer(X_test) # use compatible X_train data to the selected model\n",
    "\n",
    "# Create a summary plot of SHAP values. You can change feature names properly by sending feature name list to feature_names parameter\n",
    "shap.summary_plot(shap_values[:, :, 1], plot_type=\"dot\", max_display=25, show=False, plot_size=[15,15], feature_names=X_test.columns.values)\n",
    "\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.set_xlabel(\"SHAP value (impact on model output)\", fontsize=18)\n",
    "cb_ax = fig.axes[0] \n",
    "cb_ax.tick_params(labelsize=18)\n",
    "cb_ax.set_ylabel(\"Feature value\", fontsize=18)\n",
    "# Save the plot\n",
    "#plt.savefig(os.path.join(''Global_SHAP_plot.jpeg' ,bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ba5df",
   "metadata": {},
   "source": [
    "# With feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of best features to select. We tried with 10,15,20,25,30\n",
    "best_n = 15 \n",
    "\n",
    "# Function to get the most important features using ReliefF algorithm\n",
    "def get_important_features(best_n, X_train_feat, Y_train_feat):\n",
    "    original_X = X_train\n",
    "    # Initialize the ReliefF feature selector. Tune parameters\n",
    "    fs = ReliefF(n_features_to_select=best_n, n_neighbors=0.2) #check this, it was 0.5 but that seems like a lot\n",
    "    fs.fit(X_train_feat, Y_train_feat)\n",
    "\n",
    "    # Create a dictionary to store feature scores\n",
    "    feat_dict = {}\n",
    "    # Store feature scores in the dictionary\n",
    "    for feature_name, feature_score in zip(original_X.columns,\n",
    "                                           fs.feature_importances_):\n",
    "        feat_dict[feature_name] = feature_score\n",
    "\n",
    "    # Sort and select the most important features\n",
    "    feat_names = []\n",
    "    sorted_feat_dict = sorted(feat_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract the top 'best_n' features\n",
    "    best = sorted_feat_dict[: best_n]\n",
    "\n",
    "    # Store the names of the selected features\n",
    "    for i in best:\n",
    "        feat_names.append(i[0])\n",
    "\n",
    "    return feat_names\n",
    "\n",
    "features = get_important_features(best_n, \n",
    "                                  X_train_imputed.to_numpy(), # doesn't work with missing values \n",
    "                                  Y_train.to_numpy())\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21295385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with selected features\n",
    "X_train_feat = X_train[features]\n",
    "X_test_feat = X_test[features]\n",
    "\n",
    "X_train_feat_imputed_ = X_train_imputed[features]\n",
    "X_test_feat_imputed_ = X_test_imputed[features]\n",
    "\n",
    "# Train models using the specified list of machine learning models\n",
    "# Here I used same models in approach 1\n",
    "# TODO: Create new instances of each model here, and then perform tuning and training on them anew\n",
    "\n",
    "# List of machine learning models to train\n",
    "models = [xgboost]#, lgb, catboost, adaboost, rf, lr]\n",
    "\n",
    "trained_models_case2 = init(models, X_train_feat, X_test_feat, \n",
    "                            X_train_feat_imputed_, X_test_feat_imputed_, \n",
    "                            Y_train, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3747e7b-8fc2-4de6-ac3a-0d52c4d33208",
   "metadata": {},
   "source": [
    "## SHAP values with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d632a34-572c-4fec-ba1f-51e5c7e32f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global SHAP plots\n",
    "\n",
    "# Select the model you want to explain (XGBClassifier in this case)\n",
    "selected_model = trained_models_case2['XGBClassifier']\n",
    "\n",
    "# Create an explainer using SHAP\n",
    "explainer = shap.Explainer(selected_model, X_train_feat)\n",
    "\n",
    "# Calculate SHAP values for the data using the explainer\n",
    "shap_values = explainer(X_test_feat) # use compatible X_train data to the selected model\n",
    "\n",
    "# Create a summary plot of SHAP values. You can change feature names properly by sending feature name list to feature_names parameter\n",
    "shap.summary_plot(shap_values[:, :, 1], plot_type=\"dot\", max_display=25, show=False, plot_size=[15,15], \n",
    "                  feature_names=X_test_feat.columns.values)\n",
    "\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.set_xlabel(\"SHAP value (impact on model output)\", fontsize=18)\n",
    "cb_ax = fig.axes[0] \n",
    "cb_ax.tick_params(labelsize=18)\n",
    "cb_ax.set_ylabel(\"Feature value\", fontsize=18)\n",
    "# Save the plot\n",
    "#plt.savefig(os.path.join(''Global_SHAP_plot.jpeg' ,bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca941f5d-7dc8-4331-8b6c-adecfe315f8c",
   "metadata": {},
   "source": [
    "## # WARNING!!! ALWAYS CLEAN THIS CELL BEFORE COMMITTING, CONTAINS PATIENT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local SHAP plot - Force plot\n",
    "\n",
    "row_to_show = 0\n",
    "data_for_prediction = X_test_feat.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\n",
    "\n",
    "shap.initjs()\n",
    "shap_values = explainer(X_test_feat.iloc[[row_to_show]]) # use compatible X_train data to the selected model\n",
    "shap.force_plot(explainer.expected_value[1], shap_values.values[:,:,1], data_for_prediction, link='logit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36531fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified the force plot to improve clarity and highlight feature interactions\n",
    "def local_shap_plot(df, data, shap_values):\n",
    "    \n",
    "    # Set the threshold to filter out small SHAP values. here it's set to 0. change it\n",
    "    threshold = 0.00\n",
    "    sv_ = []\n",
    "    features_ = []\n",
    "    \n",
    "    # Map feature names to corresponding data values\n",
    "    mapping = dict(zip(df.columns.tolist(), list(data)))\n",
    "    feature_data = [f\"{feature}={mapping[feature]}\" for feature in mapping]\n",
    "\n",
    "    # Filter out zero SHAP values and corresponding feature data\n",
    "    for sv, feature in zip(shap_values, feature_data):\n",
    "        sv_.append(sv)\n",
    "        features_.append(feature)\n",
    "\n",
    "    # Sort the features and SHAP values in descending order\n",
    "    sorted_features = [feature for _, feature in sorted(zip(sv_, features_), reverse=True)]\n",
    "    sorted_sv = sorted(sv_, reverse=True)\n",
    "    \n",
    "    # Assign colors based on positive or negative SHAP values\n",
    "    colors = ['crimson' if sv >= 0 else 'dodgerblue' for sv in sorted_sv]\n",
    "\n",
    "    # Create the bar plot\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.barh(sorted_features, sorted_sv, color=colors, left=threshold)\n",
    "\n",
    "    # Show top values at the top of the plot\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel('SHAP value', fontsize=18)\n",
    "    plt.ylabel('Feature value', fontsize=18)\n",
    "    plt.savefig('MS_Male_Local.jpeg', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5d868-b4aa-4bd1-aa08-d1a4942941a7",
   "metadata": {},
   "source": [
    "## # WARNING!!! ALWAYS CLEAN THIS CELL BEFORE COMMITTING, CONTAINS PATIENT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_show = 0\n",
    "data_for_prediction = X_test_feat.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\n",
    "\n",
    "# calculate shap values\n",
    "shap_values = explainer(X_test_feat.iloc[[row_to_show]])\n",
    "\n",
    "# Extract the SHAP values for class 1 ( change to 0 if needed)\n",
    "shap_values_class0 = shap_values.values[:, :, 1][0]\n",
    "\n",
    "local_shap_plot(X_test_feat, data_for_prediction, shap_values_class0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
